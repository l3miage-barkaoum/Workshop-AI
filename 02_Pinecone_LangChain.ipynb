{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e750f6c3",
   "metadata": {},
   "source": [
    "# Diving into Pinecone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7cbed3-2e99-4f08-b24d-18567a1ef576",
   "metadata": {},
   "source": [
    "## Vector database\n",
    "\n",
    "Learn with https://docs.pinecone.io/docs/overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3793fa-5d46-4d0c-bacc-0034db1617e1",
   "metadata": {},
   "source": [
    "## Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba41b0ef-9182-4fd1-abed-312f98910bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from -r ./requirements.txt (line 2)) (0.1.13)\n",
      "Requirement already satisfied: langchain-core in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from -r ./requirements.txt (line 3)) (0.1.33)\n",
      "Requirement already satisfied: langchain_experimental in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from -r ./requirements.txt (line 4)) (0.0.55)\n",
      "Requirement already satisfied: pinecone-client in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from -r ./requirements.txt (line 5)) (3.1.0)\n",
      "Requirement already satisfied: cohere in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from -r ./requirements.txt (line 6)) (5.0.2)\n",
      "Requirement already satisfied: transformers in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from -r ./requirements.txt (line 7)) (4.39.0)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from -r ./requirements.txt (line 8)) (1.0.1)\n",
      "Requirement already satisfied: torch in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from -r ./requirements.txt (line 9)) (2.2.1)\n",
      "Requirement already satisfied: jupyterlab in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from -r ./requirements.txt (line 10)) (4.1.5)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from langchain->-r ./requirements.txt (line 2)) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from langchain->-r ./requirements.txt (line 2)) (2.0.28)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from langchain->-r ./requirements.txt (line 2)) (3.9.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from langchain->-r ./requirements.txt (line 2)) (0.6.4)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from langchain->-r ./requirements.txt (line 2)) (1.33)\n",
      "Requirement already satisfied: langchain-community<0.1,>=0.0.29 in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from langchain->-r ./requirements.txt (line 2)) (0.0.29)\n",
      "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from langchain->-r ./requirements.txt (line 2)) (0.0.1)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from langchain->-r ./requirements.txt (line 2)) (0.1.31)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from langchain->-r ./requirements.txt (line 2)) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from langchain->-r ./requirements.txt (line 2)) (2.6.4)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from langchain->-r ./requirements.txt (line 2)) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from langchain->-r ./requirements.txt (line 2)) (8.2.3)\n",
      "Requirement already satisfied: anyio<5,>=3 in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from langchain-core->-r ./requirements.txt (line 3)) (4.3.0)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from langchain-core->-r ./requirements.txt (line 3)) (23.2)\n",
      "Requirement already satisfied: certifi>=2019.11.17 in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from pinecone-client->-r ./requirements.txt (line 5)) (2024.2.2)\n",
      "Requirement already satisfied: tqdm>=4.64.1 in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from pinecone-client->-r ./requirements.txt (line 5)) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from pinecone-client->-r ./requirements.txt (line 5)) (4.10.0)\n",
      "Requirement already satisfied: urllib3>=1.26.5 in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from pinecone-client->-r ./requirements.txt (line 5)) (2.2.1)\n",
      "Requirement already satisfied: httpx>=0.21.2 in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from cohere->-r ./requirements.txt (line 6)) (0.27.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from transformers->-r ./requirements.txt (line 7)) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from transformers->-r ./requirements.txt (line 7)) (0.21.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from transformers->-r ./requirements.txt (line 7)) (2023.12.25)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from transformers->-r ./requirements.txt (line 7)) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from transformers->-r ./requirements.txt (line 7)) (0.4.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from torch->-r ./requirements.txt (line 9)) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from torch->-r ./requirements.txt (line 9)) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from torch->-r ./requirements.txt (line 9)) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from torch->-r ./requirements.txt (line 9)) (2024.3.1)\n",
      "Requirement already satisfied: async-lru>=1.0.0 in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from jupyterlab->-r ./requirements.txt (line 10)) (2.0.4)\n",
      "Requirement already satisfied: ipykernel in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from jupyterlab->-r ./requirements.txt (line 10)) (6.29.3)\n",
      "Requirement already satisfied: jupyter-core in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from jupyterlab->-r ./requirements.txt (line 10)) (5.7.2)\n",
      "Requirement already satisfied: jupyter-lsp>=2.0.0 in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from jupyterlab->-r ./requirements.txt (line 10)) (2.2.4)\n",
      "Requirement already satisfied: jupyter-server<3,>=2.4.0 in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from jupyterlab->-r ./requirements.txt (line 10)) (2.13.0)\n",
      "Requirement already satisfied: jupyterlab-server<3,>=2.19.0 in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from jupyterlab->-r ./requirements.txt (line 10)) (2.25.4)\n",
      "Requirement already satisfied: notebook-shim>=0.2 in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from jupyterlab->-r ./requirements.txt (line 10)) (0.2.4)\n",
      "Requirement already satisfied: tornado>=6.2.0 in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from jupyterlab->-r ./requirements.txt (line 10)) (6.4)\n",
      "Requirement already satisfied: traitlets in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from jupyterlab->-r ./requirements.txt (line 10)) (5.14.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r ./requirements.txt (line 2)) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r ./requirements.txt (line 2)) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r ./requirements.txt (line 2)) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r ./requirements.txt (line 2)) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r ./requirements.txt (line 2)) (1.9.4)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from anyio<5,>=3->langchain-core->-r ./requirements.txt (line 3)) (3.6)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from anyio<5,>=3->langchain-core->-r ./requirements.txt (line 3)) (1.3.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain->-r ./requirements.txt (line 2)) (3.21.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain->-r ./requirements.txt (line 2)) (0.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from httpx>=0.21.2->cohere->-r ./requirements.txt (line 6)) (1.0.4)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from httpcore==1.*->httpx>=0.21.2->cohere->-r ./requirements.txt (line 6)) (0.14.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from jinja2->torch->-r ./requirements.txt (line 9)) (2.1.5)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain->-r ./requirements.txt (line 2)) (2.4)\n",
      "Requirement already satisfied: argon2-cffi in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->-r ./requirements.txt (line 10)) (23.1.0)\n",
      "Requirement already satisfied: jupyter-client>=7.4.4 in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->-r ./requirements.txt (line 10)) (8.6.1)\n",
      "Requirement already satisfied: jupyter-events>=0.9.0 in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->-r ./requirements.txt (line 10)) (0.10.0)\n",
      "Requirement already satisfied: jupyter-server-terminals in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->-r ./requirements.txt (line 10)) (0.5.3)\n",
      "Requirement already satisfied: nbconvert>=6.4.4 in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->-r ./requirements.txt (line 10)) (7.16.2)\n",
      "Requirement already satisfied: nbformat>=5.3.0 in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->-r ./requirements.txt (line 10)) (5.10.3)\n",
      "Requirement already satisfied: overrides in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->-r ./requirements.txt (line 10)) (7.7.0)\n",
      "Requirement already satisfied: prometheus-client in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->-r ./requirements.txt (line 10)) (0.20.0)\n",
      "Requirement already satisfied: pywinpty in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->-r ./requirements.txt (line 10)) (2.0.13)\n",
      "Requirement already satisfied: pyzmq>=24 in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->-r ./requirements.txt (line 10)) (25.1.2)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->-r ./requirements.txt (line 10)) (1.8.2)\n",
      "Requirement already satisfied: terminado>=0.8.3 in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->-r ./requirements.txt (line 10)) (0.18.1)\n",
      "Requirement already satisfied: websocket-client in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from jupyter-server<3,>=2.4.0->jupyterlab->-r ./requirements.txt (line 10)) (1.7.0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from jupyter-core->jupyterlab->-r ./requirements.txt (line 10)) (4.2.0)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from jupyter-core->jupyterlab->-r ./requirements.txt (line 10)) (306)\n",
      "Requirement already satisfied: babel>=2.10 in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from jupyterlab-server<3,>=2.19.0->jupyterlab->-r ./requirements.txt (line 10)) (2.14.0)\n",
      "Requirement already satisfied: json5>=0.9.0 in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from jupyterlab-server<3,>=2.19.0->jupyterlab->-r ./requirements.txt (line 10)) (0.9.24)\n",
      "Requirement already satisfied: jsonschema>=4.18.0 in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from jupyterlab-server<3,>=2.19.0->jupyterlab->-r ./requirements.txt (line 10)) (4.21.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain->-r ./requirements.txt (line 2)) (3.9.15)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from pydantic<3,>=1->langchain->-r ./requirements.txt (line 2)) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from pydantic<3,>=1->langchain->-r ./requirements.txt (line 2)) (2.16.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from requests<3,>=2->langchain->-r ./requirements.txt (line 2)) (3.3.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain->-r ./requirements.txt (line 2)) (3.0.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from tqdm>=4.64.1->pinecone-client->-r ./requirements.txt (line 5)) (0.4.6)\n",
      "Requirement already satisfied: comm>=0.1.1 in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from ipykernel->jupyterlab->-r ./requirements.txt (line 10)) (0.2.2)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from ipykernel->jupyterlab->-r ./requirements.txt (line 10)) (1.8.1)\n",
      "Requirement already satisfied: ipython>=7.23.1 in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from ipykernel->jupyterlab->-r ./requirements.txt (line 10)) (8.22.2)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from ipykernel->jupyterlab->-r ./requirements.txt (line 10)) (0.1.6)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from ipykernel->jupyterlab->-r ./requirements.txt (line 10)) (1.6.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from ipykernel->jupyterlab->-r ./requirements.txt (line 10)) (5.9.8)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from sympy->torch->-r ./requirements.txt (line 9)) (1.3.0)\n",
      "Requirement already satisfied: decorator in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from ipython>=7.23.1->ipykernel->jupyterlab->-r ./requirements.txt (line 10)) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from ipython>=7.23.1->ipykernel->jupyterlab->-r ./requirements.txt (line 10)) (0.19.1)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from ipython>=7.23.1->ipykernel->jupyterlab->-r ./requirements.txt (line 10)) (3.0.43)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from ipython>=7.23.1->ipykernel->jupyterlab->-r ./requirements.txt (line 10)) (2.17.2)\n",
      "Requirement already satisfied: stack-data in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from ipython>=7.23.1->ipykernel->jupyterlab->-r ./requirements.txt (line 10)) (0.6.3)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.19.0->jupyterlab->-r ./requirements.txt (line 10)) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.19.0->jupyterlab->-r ./requirements.txt (line 10)) (0.34.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.19.0->jupyterlab->-r ./requirements.txt (line 10)) (0.18.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from jupyter-client>=7.4.4->jupyter-server<3,>=2.4.0->jupyterlab->-r ./requirements.txt (line 10)) (2.9.0.post0)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->-r ./requirements.txt (line 10)) (2.0.7)\n",
      "Requirement already satisfied: rfc3339-validator in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->-r ./requirements.txt (line 10)) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->-r ./requirements.txt (line 10)) (0.1.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab->-r ./requirements.txt (line 10)) (4.12.3)\n",
      "Requirement already satisfied: bleach!=5.0.0 in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab->-r ./requirements.txt (line 10)) (6.1.0)\n",
      "Requirement already satisfied: defusedxml in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab->-r ./requirements.txt (line 10)) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab->-r ./requirements.txt (line 10)) (0.3.0)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab->-r ./requirements.txt (line 10)) (3.0.2)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab->-r ./requirements.txt (line 10)) (0.10.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab->-r ./requirements.txt (line 10)) (1.5.1)\n",
      "Requirement already satisfied: tinycss2 in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab->-r ./requirements.txt (line 10)) (1.2.1)\n",
      "Requirement already satisfied: fastjsonschema in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from nbformat>=5.3.0->jupyter-server<3,>=2.4.0->jupyterlab->-r ./requirements.txt (line 10)) (2.19.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain->-r ./requirements.txt (line 2)) (1.0.0)\n",
      "Requirement already satisfied: argon2-cffi-bindings in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from argon2-cffi->jupyter-server<3,>=2.4.0->jupyterlab->-r ./requirements.txt (line 10)) (21.2.0)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from bleach!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab->-r ./requirements.txt (line 10)) (1.16.0)\n",
      "Requirement already satisfied: webencodings in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from bleach!=5.0.0->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab->-r ./requirements.txt (line 10)) (0.5.1)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->jupyterlab->-r ./requirements.txt (line 10)) (0.8.3)\n",
      "Requirement already satisfied: fqdn in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->-r ./requirements.txt (line 10)) (1.5.1)\n",
      "Requirement already satisfied: isoduration in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->-r ./requirements.txt (line 10)) (20.11.0)\n",
      "Requirement already satisfied: uri-template in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->-r ./requirements.txt (line 10)) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=1.11 in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->-r ./requirements.txt (line 10)) (1.13)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel->jupyterlab->-r ./requirements.txt (line 10)) (0.2.13)\n",
      "Requirement already satisfied: cffi>=1.0.1 in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from argon2-cffi-bindings->argon2-cffi->jupyter-server<3,>=2.4.0->jupyterlab->-r ./requirements.txt (line 10)) (1.16.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from beautifulsoup4->nbconvert>=6.4.4->jupyter-server<3,>=2.4.0->jupyterlab->-r ./requirements.txt (line 10)) (2.5)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyterlab->-r ./requirements.txt (line 10)) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyterlab->-r ./requirements.txt (line 10)) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyterlab->-r ./requirements.txt (line 10)) (0.2.2)\n",
      "Requirement already satisfied: pycparser in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->jupyter-server<3,>=2.4.0->jupyterlab->-r ./requirements.txt (line 10)) (2.21)\n",
      "Requirement already satisfied: arrow>=0.15.0 in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->-r ./requirements.txt (line 10)) (1.3.0)\n",
      "Requirement already satisfied: types-python-dateutil>=2.8.10 in c:\\users\\barkaoui\\desktop\\m2\\workshop-ai\\myvenv3\\lib\\site-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->-r ./requirements.txt (line 10)) (2.9.0.20240316)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -r ./requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e292ae-e318-4eaf-93b0-0d28484ec6f7",
   "metadata": {},
   "source": [
    "### Verify Pinecone is installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b30f952",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Barkaoui\\Desktop\\M2\\Workshop-AI\\myvenv3\\Lib\\site-packages\\pinecone\\data\\index.py:1: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from pinecone import Pinecone\n",
    "\n",
    "# loading the API Keys (Cohere, Pinecone) from .env\n",
    "load_dotenv(find_dotenv(), override=True)\n",
    "\n",
    "# Initialize Pinecone library with API key and environment\n",
    "pinecone = Pinecone(\n",
    "    api_key=os.environ.get('PINECONE_API_KEY')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f99ddb",
   "metadata": {},
   "source": [
    "## Pinecone Indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd539ee-a420-49d1-8d80-4df1de09087a",
   "metadata": {},
   "source": [
    "Learn with https://docs.pinecone.io/docs/indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2dcf962c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'indexes': [{'dimension': 1536,\n",
       "              'host': 'langchain-pinecone-iqzzxc5.svc.gcp-starter.pinecone.io',\n",
       "              'metric': 'cosine',\n",
       "              'name': 'langchain-pinecone',\n",
       "              'spec': {'pod': {'environment': 'gcp-starter',\n",
       "                               'pod_type': 'starter',\n",
       "                               'pods': 1,\n",
       "                               'replicas': 1,\n",
       "                               'shards': 1}},\n",
       "              'status': {'ready': True, 'state': 'Ready'}}]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List all indexes in the Pinecone environment\n",
    "pinecone.list_indexes()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca26c84",
   "metadata": {},
   "source": [
    "### Creating an index\n",
    "\n",
    "Firstly, go to the section Deleting an index and delete the index from the leson 01 \"churchill-speech\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2cf9dc13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating index langchain-pinecone ....\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "from pinecone import PodSpec\n",
    "\n",
    "# Specify name for index\n",
    "index_name = 'langchain-pinecone'\n",
    "\n",
    "#  Check if index already exists\n",
    "if index_name not in pinecone.list_indexes():\n",
    "    print(f'Creating index {index_name} ....')\n",
    "\n",
    "    # Create index with parameters\n",
    "    pinecone.create_index(index_name, \n",
    "                          # Vector dimension - The number of dimensions for vectors in this index\n",
    "                          dimension=1536, \n",
    "                          # Similarity metric \n",
    "                          # Distance measure used to compare vectors\n",
    "                          # 'cosine' measures the cosine similarity between vectors\n",
    "                          metric='cosine',\n",
    "                          spec=PodSpec(\n",
    "                            environment=\"gcp-starter\")\n",
    "                          )\n",
    "                        \n",
    "    print('Done')\n",
    "else:\n",
    "    print(f'Index {index_name} already exists!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "495a27d9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'langchain' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Retrieve metadata about the index \u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m pinecone\u001b[38;5;241m.\u001b[39mdescribe_index(\u001b[43mlangchain\u001b[49m\u001b[38;5;241m-\u001b[39mpinecone)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'langchain' is not defined"
     ]
    }
   ],
   "source": [
    "# Retrieve metadata about the index \n",
    "pinecone.describe_index(index_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e341740",
   "metadata": {},
   "source": [
    "### Deleting an index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84d5dbc1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter Pinecone index to delete :  langchain-pinecone\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index langchain-pinecone does not exist!\n"
     ]
    }
   ],
   "source": [
    "# Get index name to delete from user input\n",
    "index_name = input('Enter Pinecone index to delete : ')\n",
    "\n",
    "list_indexes = pinecone.list_indexes()\n",
    "\n",
    "# Check if index exists \n",
    "if index_name in pinecone.list_indexes().names():\n",
    "    print(f'Deleting index {index_name} ... ')\n",
    "    pinecone.delete_index(index_name)\n",
    "    print('Done')\n",
    "else:\n",
    "    print(f'Index {index_name} does not exist!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca8ea69",
   "metadata": {},
   "source": [
    "### Getting index statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7322f767",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "index_name = 'langchain-pinecone'\n",
    "\n",
    "# Create index with parameters\n",
    "pinecone.create_index(index_name, \n",
    "                          # Vector dimension - The number of dimensions for vectors in this index\n",
    "                          dimension=1536, \n",
    "                          # Similarity metric \n",
    "                          # Distance measure used to compare vectors\n",
    "                          # 'cosine' measures the cosine similarity between vectors\n",
    "                          metric='cosine',\n",
    "                          spec=PodSpec(\n",
    "                            environment=\"gcp-starter\")\n",
    "                          )\n",
    "# index object\n",
    "index = pinecone.Index(index_name)\n",
    "\n",
    "# Retrieve usage statistics for the index\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5147f643",
   "metadata": {},
   "source": [
    "### Inserting into an index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2edc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# inserting some random vectors into a Pinecone index\n",
    "\n",
    "# Generate 5 random 1536-dim vectors \n",
    "vectors = [[random.random() for _ in range(1536)] for v in range(5)]\n",
    "\n",
    "# Create a list of IDs to associate with each vector\n",
    "ids = list('abcde')\n",
    "\n",
    "# Specify Pinecone index name \n",
    "index_name = 'langchain-pinecone'\n",
    "\n",
    "# Create index object\n",
    "index = pinecone.Index(index_name)\n",
    "\n",
    "# Upsert vectors into index\n",
    "index.upsert(vectors=zip(ids, vectors))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0088eb3e",
   "metadata": {},
   "source": [
    "### Updating a vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503b8bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upsert a single vector to update it\n",
    "\n",
    "# Vector ID to update\n",
    "id_to_update = 'c'  \n",
    "\n",
    "# New vector data \n",
    "new_vector = [0.3] * 1536\n",
    "\n",
    "# Upsert the new vector data with the same ID\n",
    "index.upsert(vectors=[(id_to_update, new_vector)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3f3f45",
   "metadata": {},
   "source": [
    "### Fetching a vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a74988a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get index object\n",
    "index = pinecone.Index('langchain-pinecone')  \n",
    "\n",
    "# Specify IDs of vectors to fetch\n",
    "ids_to_fetch = ['c', 'd']\n",
    "\n",
    "# Fetch vector data for the provided IDs\n",
    "index.fetch(ids=ids_to_fetch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a809374",
   "metadata": {},
   "source": [
    "### Deleting vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b067c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify IDs of vectors to delete\n",
    "ids_to_delete = ['b', 'c']  \n",
    "\n",
    "# Delete the vectors for those IDs\n",
    "index.delete(ids=ids_to_delete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138d278c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get index statistics\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d1288f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to fetch a deleted vector \n",
    "index.fetch(ids=['b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f99f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete all remaining vectors\n",
    "index.delete(delete_all=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4595be07",
   "metadata": {},
   "source": [
    "## Splitting and Embedding Text Using LangChain\n",
    "\n",
    "https://python.langchain.com/docs/modules/data_connection/document_transformers/\n",
    "https://python.langchain.com/docs/integrations/text_embedding/cohere\n",
    "\n",
    "**Text Splitting**\n",
    "\n",
    "- Splitting large text documents into smaller pieces called chunks\n",
    "- Makes large texts more manageable to process \n",
    "- Common splitting approaches:\n",
    "  - Split by fixed character length \n",
    "  - Split at semantic boundaries like sentences or topics\n",
    "  - Use a sliding window to create overlapping chunks\n",
    "- Output is a list of text chunks from the original document\n",
    "\n",
    "**Text Embedding**\n",
    "\n",
    "- Encoding text into numeric vectors that capture semantic meaning\n",
    "- Steps:\n",
    "  1. Turn text into chunks (splitting)\n",
    "  2. Map chunks to vector embeddings\n",
    "  3. Aggregate chunks embeddings into a vector database\n",
    " \n",
    "\n",
    "**Goals**\n",
    "- The goal of splitting is to divide large documents into manageable sizes for processing\n",
    "- The goal of embedding is to encode semantic meaning in a way that allows for semantic search \n",
    "and comparison\n",
    "- Together, splitting and embedding enable semantic search, QA, and analysis of large text corpora by indexing the vectorized content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8954ee0b-0f4c-49f2-b0d3-16e5465e1a06",
   "metadata": {},
   "source": [
    "### Split document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc86f006-a9b3-4bd8-a9ec-25bcdf97ad6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Open text file and read contents into churchill_speech\n",
    "with open('documents/churchill_speech.txt') as f:\n",
    "    churchill_speech = f.read()\n",
    "\n",
    "# Create text splitter instance\n",
    "# check this video about chunk - https://youtu.be/n0uPzvGTFI0?feature=shared\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, # maximum size of text chunk in number of characters\n",
    "    chunk_overlap=20, # pecifies the number of overlapping characters between adjacent chunks.\n",
    "                      # if chunk 1 ends at character 100, chunk 2 will start at character 80\n",
    ")\n",
    "\n",
    "# Split the text into chunks\n",
    "chunks = text_splitter.create_documents([churchill_speech])\n",
    "\n",
    "# Print specific chunks - you can test it\n",
    "# print(chunks[2]) \n",
    "# print(chunks[10].page_content)\n",
    "print(f'Now you have {len(chunks)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0467288-9b84-4484-939f-89366bd740e8",
   "metadata": {},
   "source": [
    "### Create Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cde0230-ff20-4f0d-bef4-ddb2bbb71a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import CohereEmbeddings\n",
    "\n",
    "# Create embeddings instance\n",
    "embeddings = CohereEmbeddings()\n",
    "\n",
    "# Take first text chunk \n",
    "first_chunk = chunks[0]\n",
    "\n",
    "# Embed the text into a vector \n",
    "vector = embeddings.embed_query(first_chunk.page_content)\n",
    "\n",
    "\n",
    "# Print the chunk\n",
    "print(first_chunk.page_content)\n",
    "# Print the vector\n",
    "print(vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d098ed-8021-443c-a6c2-6e4938915368",
   "metadata": {},
   "source": [
    "### Inserting the Embeddings into a Pinecone Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83d3f40-7dc1-4db1-be48-f1d2d11b362d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pinecone import Pinecone, PodSpec\n",
    "from langchain.vectorstores import Pinecone as Pinecone_langchain\n",
    "\n",
    "# Initialize Pinecone client \n",
    "pinecone = Pinecone(\n",
    "    api_key=os.environ.get('PINECONE_API_KEY')\n",
    ")\n",
    "\n",
    "# Delete any existing indexes\n",
    "indexes = pinecone.list_indexes().names()\n",
    "for i in indexes:\n",
    "  print('Deleting all indexes ... ', end='')\n",
    "  pinecone.delete_index(i)\n",
    "  print('Done')\n",
    "\n",
    "# Create a new index\n",
    "index_name = 'churchill-speech'\n",
    "if index_name not in pinecone.list_indexes():\n",
    "  print(f'Creating index {index_name} ...')\n",
    "  pinecone.create_index(index_name, dimension=4096, metric='cosine',spec=PodSpec(environment=\"gcp-starter\"))\n",
    "  print('Done!')\n",
    "\n",
    "# Index the text chunks into Pinecone \n",
    "vector_store = Pinecone_langchain.from_documents(chunks, embeddings, index_name=index_name)\n",
    "print(\"Vector store created !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd109274-9bf8-4962-b262-059de734062c",
   "metadata": {},
   "source": [
    "## Asking Questions (Similarity Search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8dc435-2caf-4d98-bb8e-4269c7822ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query text \n",
    "query = 'What are the emotions of the speech?'\n",
    "\n",
    "# Semantic search against indexed chunks\n",
    "result = vector_store.similarity_search(query)\n",
    "\n",
    "# Print top result \n",
    "print(result)\n",
    "\n",
    "# Clean output\n",
    "print('-' * 50)\n",
    "for r in result:\n",
    "    print(r.page_content)\n",
    "    print('-' * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8b127f-04f5-4bde-943c-cea765095a22",
   "metadata": {},
   "source": [
    "## Answering in Natural Language using an LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e066c5d0-b32c-4115-aa9f-e21b9fed99b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import RetrievalQA and Chat model\n",
    "from langchain.chains import RetrievalQA  \n",
    "from langchain.llms import Cohere\n",
    "\n",
    "# Create Cohere model \n",
    "llm = Cohere(temperature=0.75, cohere_api_key=os.environ.get('COHERE_API_KEY'))\n",
    "\n",
    "# Create retriever from vector store\n",
    "retriever = vector_store.as_retriever(\n",
    "    # specifies to use semantic similarity search against the Pinecone index\n",
    "    search_type='similarity', \n",
    "    # Here we set k=10 to retrieve the top 10 most similar results\n",
    "    search_kwargs={'k': 10}) \n",
    "\n",
    "# Build QA chain with retriever \n",
    "chain = RetrievalQA.from_chain_type(llm=llm, \n",
    "                                    # builds a \"stuff\" chain that retrieves context for questions\n",
    "                                    # you can have more details with - https://chat.langchain.com/\n",
    "                                    chain_type=\"stuff\", \n",
    "                                    retriever=retriever)\n",
    "\n",
    "# Query the chain\n",
    "query = \"What are the emotions of this speech?\"\n",
    "answer = chain.invoke(query)\n",
    "\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c62abb-b177-4569-b719-7c803d56138f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
