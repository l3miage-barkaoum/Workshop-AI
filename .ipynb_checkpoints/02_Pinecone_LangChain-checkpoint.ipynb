{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e750f6c3",
   "metadata": {},
   "source": [
    "# Diving into Pinecone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7cbed3-2e99-4f08-b24d-18567a1ef576",
   "metadata": {},
   "source": [
    "## Vector database\n",
    "\n",
    "Learn with https://docs.pinecone.io/docs/overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3793fa-5d46-4d0c-bacc-0034db1617e1",
   "metadata": {},
   "source": [
    "## Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba41b0ef-9182-4fd1-abed-312f98910bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -r ./requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e292ae-e318-4eaf-93b0-0d28484ec6f7",
   "metadata": {},
   "source": [
    "### Verify Pinecone is installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b30f952",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from pinecone import Pinecone\n",
    "\n",
    "# loading the API Keys (Cohere, Pinecone) from .env\n",
    "load_dotenv(find_dotenv(), override=True)\n",
    "\n",
    "# Initialize Pinecone library with API key and environment\n",
    "pinecone = Pinecone(\n",
    "    api_key=os.environ.get('PINECONE_API_KEY')\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f99ddb",
   "metadata": {},
   "source": [
    "## Pinecone Indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd539ee-a420-49d1-8d80-4df1de09087a",
   "metadata": {},
   "source": [
    "Learn with https://docs.pinecone.io/docs/indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dcf962c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all indexes in the Pinecone environment\n",
    "pinecone.list_indexes()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca26c84",
   "metadata": {},
   "source": [
    "### Creating an index\n",
    "\n",
    "Firstly, go to the section Deleting an index and delete the index from the leson 01 \"churchill-speech\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf9dc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import PodSpec\n",
    "\n",
    "# Specify name for index\n",
    "index_name = 'langchain-pinecone'\n",
    "\n",
    "#  Check if index already exists\n",
    "if index_name not in pinecone.list_indexes():\n",
    "    print(f'Creating index {index_name} ....')\n",
    "\n",
    "    # Create index with parameters\n",
    "    pinecone.create_index(index_name, \n",
    "                          # Vector dimension - The number of dimensions for vectors in this index\n",
    "                          dimension=1536, \n",
    "                          # Similarity metric \n",
    "                          # Distance measure used to compare vectors\n",
    "                          # 'cosine' measures the cosine similarity between vectors\n",
    "                          metric='cosine',\n",
    "                          spec=PodSpec(\n",
    "                            environment=\"gcp-starter\")\n",
    "                          )\n",
    "                        \n",
    "    print('Done')\n",
    "else:\n",
    "    print(f'Index {index_name} already exists!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495a27d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve metadata about the index \n",
    "pinecone.describe_index(index_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e341740",
   "metadata": {},
   "source": [
    "### Deleting an index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d5dbc1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get index name to delete from user input\n",
    "index_name = input('Enter Pinecone index to delete : ')\n",
    "\n",
    "list_indexes = pinecone.list_indexes()\n",
    "\n",
    "# Check if index exists \n",
    "if index_name in pinecone.list_indexes().names():\n",
    "    print(f'Deleting index {index_name} ... ')\n",
    "    pinecone.delete_index(index_name)\n",
    "    print('Done')\n",
    "else:\n",
    "    print(f'Index {index_name} does not exist!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca8ea69",
   "metadata": {},
   "source": [
    "### Getting index statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7322f767",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "index_name = 'langchain-pinecone'\n",
    "\n",
    "# Create index with parameters\n",
    "pinecone.create_index(index_name, \n",
    "                          # Vector dimension - The number of dimensions for vectors in this index\n",
    "                          dimension=1536, \n",
    "                          # Similarity metric \n",
    "                          # Distance measure used to compare vectors\n",
    "                          # 'cosine' measures the cosine similarity between vectors\n",
    "                          metric='cosine',\n",
    "                          spec=PodSpec(\n",
    "                            environment=\"gcp-starter\")\n",
    "                          )\n",
    "# index object\n",
    "index = pinecone.Index(index_name)\n",
    "\n",
    "# Retrieve usage statistics for the index\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5147f643",
   "metadata": {},
   "source": [
    "### Inserting into an index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2edc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# inserting some random vectors into a Pinecone index\n",
    "\n",
    "# Generate 5 random 1536-dim vectors \n",
    "vectors = [[random.random() for _ in range(1536)] for v in range(5)]\n",
    "\n",
    "# Create a list of IDs to associate with each vector\n",
    "ids = list('abcde')\n",
    "\n",
    "# Specify Pinecone index name \n",
    "index_name = 'langchain-pinecone'\n",
    "\n",
    "# Create index object\n",
    "index = pinecone.Index(index_name)\n",
    "\n",
    "# Upsert vectors into index\n",
    "index.upsert(vectors=zip(ids, vectors))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0088eb3e",
   "metadata": {},
   "source": [
    "### Updating a vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503b8bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upsert a single vector to update it\n",
    "\n",
    "# Vector ID to update\n",
    "id_to_update = 'c'  \n",
    "\n",
    "# New vector data \n",
    "new_vector = [0.3] * 1536\n",
    "\n",
    "# Upsert the new vector data with the same ID\n",
    "index.upsert(vectors=[(id_to_update, new_vector)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3f3f45",
   "metadata": {},
   "source": [
    "### Fetching a vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a74988a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get index object\n",
    "index = pinecone.Index('langchain-pinecone')  \n",
    "\n",
    "# Specify IDs of vectors to fetch\n",
    "ids_to_fetch = ['c', 'd']\n",
    "\n",
    "# Fetch vector data for the provided IDs\n",
    "index.fetch(ids=ids_to_fetch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a809374",
   "metadata": {},
   "source": [
    "### Deleting vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b067c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify IDs of vectors to delete\n",
    "ids_to_delete = ['b', 'c']  \n",
    "\n",
    "# Delete the vectors for those IDs\n",
    "index.delete(ids=ids_to_delete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138d278c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get index statistics\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d1288f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to fetch a deleted vector \n",
    "index.fetch(ids=['b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f99f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete all remaining vectors\n",
    "index.delete(delete_all=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4595be07",
   "metadata": {},
   "source": [
    "## Splitting and Embedding Text Using LangChain\n",
    "\n",
    "https://python.langchain.com/docs/modules/data_connection/document_transformers/\n",
    "https://python.langchain.com/docs/integrations/text_embedding/cohere\n",
    "\n",
    "**Text Splitting**\n",
    "\n",
    "- Splitting large text documents into smaller pieces called chunks\n",
    "- Makes large texts more manageable to process \n",
    "- Common splitting approaches:\n",
    "  - Split by fixed character length \n",
    "  - Split at semantic boundaries like sentences or topics\n",
    "  - Use a sliding window to create overlapping chunks\n",
    "- Output is a list of text chunks from the original document\n",
    "\n",
    "**Text Embedding**\n",
    "\n",
    "- Encoding text into numeric vectors that capture semantic meaning\n",
    "- Steps:\n",
    "  1. Turn text into chunks (splitting)\n",
    "  2. Map chunks to vector embeddings\n",
    "  3. Aggregate chunks embeddings into a vector database\n",
    " \n",
    "\n",
    "**Goals**\n",
    "- The goal of splitting is to divide large documents into manageable sizes for processing\n",
    "- The goal of embedding is to encode semantic meaning in a way that allows for semantic search \n",
    "and comparison\n",
    "- Together, splitting and embedding enable semantic search, QA, and analysis of large text corpora by indexing the vectorized content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8954ee0b-0f4c-49f2-b0d3-16e5465e1a06",
   "metadata": {},
   "source": [
    "### Split document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc86f006-a9b3-4bd8-a9ec-25bcdf97ad6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Open text file and read contents into churchill_speech\n",
    "with open('documents/churchill_speech.txt') as f:\n",
    "    churchill_speech = f.read()\n",
    "\n",
    "# Create text splitter instance\n",
    "# check this video about chunk - https://youtu.be/n0uPzvGTFI0?feature=shared\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, # maximum size of text chunk in number of characters\n",
    "    chunk_overlap=20, # pecifies the number of overlapping characters between adjacent chunks.\n",
    "                      # if chunk 1 ends at character 100, chunk 2 will start at character 80\n",
    ")\n",
    "\n",
    "# Split the text into chunks\n",
    "chunks = text_splitter.create_documents([churchill_speech])\n",
    "\n",
    "# Print specific chunks - you can test it\n",
    "# print(chunks[2]) \n",
    "# print(chunks[10].page_content)\n",
    "print(f'Now you have {len(chunks)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0467288-9b84-4484-939f-89366bd740e8",
   "metadata": {},
   "source": [
    "### Create Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cde0230-ff20-4f0d-bef4-ddb2bbb71a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import CohereEmbeddings\n",
    "\n",
    "# Create embeddings instance\n",
    "embeddings = CohereEmbeddings()\n",
    "\n",
    "# Take first text chunk \n",
    "first_chunk = chunks[0]\n",
    "\n",
    "# Embed the text into a vector \n",
    "vector = embeddings.embed_query(first_chunk.page_content)\n",
    "\n",
    "\n",
    "# Print the chunk\n",
    "print(first_chunk.page_content)\n",
    "# Print the vector\n",
    "print(vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d098ed-8021-443c-a6c2-6e4938915368",
   "metadata": {},
   "source": [
    "### Inserting the Embeddings into a Pinecone Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83d3f40-7dc1-4db1-be48-f1d2d11b362d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pinecone import Pinecone, PodSpec\n",
    "from langchain.vectorstores import Pinecone as Pinecone_langchain\n",
    "\n",
    "# Initialize Pinecone client \n",
    "pinecone = Pinecone(\n",
    "    api_key=os.environ.get('PINECONE_API_KEY')\n",
    ")\n",
    "\n",
    "# Delete any existing indexes\n",
    "indexes = pinecone.list_indexes().names()\n",
    "for i in indexes:\n",
    "  print('Deleting all indexes ... ', end='')\n",
    "  pinecone.delete_index(i)\n",
    "  print('Done')\n",
    "\n",
    "# Create a new index\n",
    "index_name = 'churchill-speech'\n",
    "if index_name not in pinecone.list_indexes():\n",
    "  print(f'Creating index {index_name} ...')\n",
    "  pinecone.create_index(index_name, dimension=4096, metric='cosine',spec=PodSpec(environment=\"gcp-starter\"))\n",
    "  print('Done!')\n",
    "\n",
    "# Index the text chunks into Pinecone \n",
    "vector_store = Pinecone_langchain.from_documents(chunks, embeddings, index_name=index_name)\n",
    "print(\"Vector store created !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd109274-9bf8-4962-b262-059de734062c",
   "metadata": {},
   "source": [
    "## Asking Questions (Similarity Search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8dc435-2caf-4d98-bb8e-4269c7822ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query text \n",
    "query = 'What are the emotions of the speech?'\n",
    "\n",
    "# Semantic search against indexed chunks\n",
    "result = vector_store.similarity_search(query)\n",
    "\n",
    "# Print top result \n",
    "print(result)\n",
    "\n",
    "# Clean output\n",
    "print('-' * 50)\n",
    "for r in result:\n",
    "    print(r.page_content)\n",
    "    print('-' * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8b127f-04f5-4bde-943c-cea765095a22",
   "metadata": {},
   "source": [
    "## Answering in Natural Language using an LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e066c5d0-b32c-4115-aa9f-e21b9fed99b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import RetrievalQA and Chat model\n",
    "from langchain.chains import RetrievalQA  \n",
    "from langchain.llms import Cohere\n",
    "\n",
    "# Create Cohere model \n",
    "llm = Cohere(temperature=0.75, cohere_api_key=os.environ.get('COHERE_API_KEY'))\n",
    "\n",
    "# Create retriever from vector store\n",
    "retriever = vector_store.as_retriever(\n",
    "    # specifies to use semantic similarity search against the Pinecone index\n",
    "    search_type='similarity', \n",
    "    # Here we set k=10 to retrieve the top 10 most similar results\n",
    "    search_kwargs={'k': 10}) \n",
    "\n",
    "# Build QA chain with retriever \n",
    "chain = RetrievalQA.from_chain_type(llm=llm, \n",
    "                                    # builds a \"stuff\" chain that retrieves context for questions\n",
    "                                    # you can have more details with - https://chat.langchain.com/\n",
    "                                    chain_type=\"stuff\", \n",
    "                                    retriever=retriever)\n",
    "\n",
    "# Query the chain\n",
    "query = \"What are the emotions of this speech?\"\n",
    "answer = chain.invoke(query)\n",
    "\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c62abb-b177-4569-b719-7c803d56138f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
